{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = 'C:\\\\Users\\\\eesha\\\\data'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cat_dir = os.path.join(train_dir, 'cat')\n",
    "\n",
    "# Directory with our training butterfly pitures\n",
    "train_butterfly_dir = os.path.join(train_dir, 'butterfly')\n",
    "\n",
    "# Directory with our training elephant pictures\n",
    "train_elephant_dir = os.path.join(train_dir, 'elephant')\n",
    "\n",
    "# Directory with our training chicken pictures\n",
    "train_chicken_dir = os.path.join(train_dir, 'chicken')\n",
    "\n",
    "# Directory with our training cow pictures\n",
    "train_cow_dir = os.path.join(train_dir, 'cow')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dog_dir = os.path.join(train_dir, 'dog')\n",
    "\n",
    "# Directory with our training horse pictures\n",
    "train_horse_dir = os.path.join(train_dir, 'horse')\n",
    "\n",
    "# Directory with our training sheep pictures\n",
    "train_sheep_dir = os.path.join(train_dir, 'sheep')\n",
    "\n",
    "# Directory with our training squirrel pictures\n",
    "train_squirrel_dir = os.path.join(train_dir, 'squirrel')\n",
    "\n",
    "# Directory with our training spider pictures\n",
    "train_spider_dir = os.path.join(train_dir, 'spider')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cat_dir = os.path.join(validation_dir, 'cat')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dog_dir = os.path.join(validation_dir, 'dog')\n",
    "\n",
    "# Directory with our validation butterfly pitures\n",
    "validation_butterfly_dir = os.path.join(validation_dir, 'butterfly')\n",
    "\n",
    "# Directory with our validation elephant pictures\n",
    "validation_elephant_dir = os.path.join(validation_dir, 'elephant')\n",
    "\n",
    "# Directory with our validation chicken pictures\n",
    "validation_chicken_dir = os.path.join(validation_dir, 'chicken')\n",
    "\n",
    "# Directory with our validation cow pictures\n",
    "validation_cow_dir = os.path.join(validation_dir, 'cow')\n",
    "\n",
    "# Directory with our validation horse pictures\n",
    "validation_horse_dir = os.path.join(validation_dir, 'horse')\n",
    "\n",
    "# Directory with our validation sheep pictures\n",
    "validation_sheep_dir = os.path.join(validation_dir, 'sheep')\n",
    "\n",
    "# Directory with our validation squirrel pictures\n",
    "validation_squirrel_dir = os.path.join(validation_dir, 'squirrel')\n",
    "\n",
    "# Directory with our validation spider pictures\n",
    "validation_spider_dir = os.path.join(validation_dir, 'spider')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\eesha\\\\data\\\\train\\\\cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-273984b99bc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpic_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrain_cat_fnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_cat_dir\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mtrain_dog_fnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_dog_dir\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\eesha\\\\data\\\\train\\\\cat'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "pic_index = 100\n",
    "train_cat_fnames = os.listdir( train_cat_dir )\n",
    "train_dog_fnames = os.listdir( train_dog_dir )\n",
    "\n",
    "\n",
    "next_cat_pix = [os.path.join(train_cat_dir, fname) \n",
    "                for fname in train_cat_fnames[ pic_index-8:pic_index] \n",
    "               ]\n",
    "\n",
    "next_dog_pix = [os.path.join(train_dog_dir, fname) \n",
    "                for fname in train_dog_fnames[ pic_index-8:pic_index]\n",
    "               ]\n",
    "# 17539\n",
    "# 8640\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "    # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "    \n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the inception model  \n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = InceptionV3(input_shape = (299, 299, 3), # Shape of our images\n",
    "                                include_top = False, # Leave out the last fully connected layer\n",
    "                                weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get('accuracy') > 0.959):\n",
    "            print(\"\\nReached 95.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           5130        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,119,658\n",
      "Trainable params: 1,316,874\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "\n",
    "out = pre_trained_model.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation = 'relu')(out)\n",
    "out = Dense(512, activation = 'relu')(out)\n",
    "total_classes = 10\n",
    "predictions = Dense(total_classes, activation = 'softmax')(out)\n",
    "\n",
    "model = Model(inputs = pre_trained_model.input, outputs = predictions)\n",
    "model.compile(Adam(lr = .0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25650 images belonging to 10 classes.\n",
      "Found 2871 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'categorical', \n",
    "                                                    target_size = (299, 299))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'categorical', \n",
    "                                                          target_size = (299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 120s 1s/step - loss: 1.3343 - accuracy: 0.6340 - val_loss: 0.6138 - val_accuracy: 0.8910\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 97s 967ms/step - loss: 0.5717 - accuracy: 0.8435 - val_loss: 0.0538 - val_accuracy: 0.9750\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 99s 986ms/step - loss: 0.4191 - accuracy: 0.8805 - val_loss: 0.1649 - val_accuracy: 0.9526\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 99s 989ms/step - loss: 0.3890 - accuracy: 0.8885 - val_loss: 0.2285 - val_accuracy: 0.9680\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 0.3353 - accuracy: 0.9080 - val_loss: 0.3287 - val_accuracy: 0.9660\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.3835 - accuracy: 0.8844 - val_loss: 0.1268 - val_accuracy: 0.9677\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.3391 - accuracy: 0.8925 - val_loss: 0.0218 - val_accuracy: 0.9610\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.3297 - accuracy: 0.8930 - val_loss: 0.1201 - val_accuracy: 0.9540\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 110s 1s/step - loss: 0.3231 - accuracy: 0.9030 - val_loss: 0.0451 - val_accuracy: 0.9667\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.2988 - accuracy: 0.9055 - val_loss: 0.2840 - val_accuracy: 0.9660\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.3300 - accuracy: 0.8935 - val_loss: 0.0154 - val_accuracy: 0.9700\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 0.3090 - accuracy: 0.9095 - val_loss: 0.0127 - val_accuracy: 0.9677\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 79s 785ms/step - loss: 0.3266 - accuracy: 0.9075 - val_loss: 0.1000 - val_accuracy: 0.9700\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 0.2844 - accuracy: 0.9120 - val_loss: 0.2931 - val_accuracy: 0.9690\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 0.2889 - accuracy: 0.9080 - val_loss: 0.0818 - val_accuracy: 0.9667\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.3157 - accuracy: 0.9040 - val_loss: 0.1554 - val_accuracy: 0.9670\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.3306 - accuracy: 0.8940 - val_loss: 0.0925 - val_accuracy: 0.9660\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.2719 - accuracy: 0.9150 - val_loss: 0.0539 - val_accuracy: 0.9667\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.2965 - accuracy: 0.9110 - val_loss: 0.3085 - val_accuracy: 0.9730\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.3154 - accuracy: 0.9040 - val_loss: 0.5846 - val_accuracy: 0.9640\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.3224 - accuracy: 0.9000 - val_loss: 0.0361 - val_accuracy: 0.9687\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 64s 640ms/step - loss: 0.2606 - accuracy: 0.9155 - val_loss: 0.0186 - val_accuracy: 0.9760\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.3026 - accuracy: 0.9045 - val_loss: 0.0650 - val_accuracy: 0.9730\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.2879 - accuracy: 0.9110 - val_loss: 0.0399 - val_accuracy: 0.9748\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.2719 - accuracy: 0.9190 - val_loss: 0.1630 - val_accuracy: 0.9690\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 61s 612ms/step - loss: 0.2760 - accuracy: 0.9115 - val_loss: 0.0150 - val_accuracy: 0.9627\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.2640 - accuracy: 0.9145 - val_loss: 0.2129 - val_accuracy: 0.9710\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.2510 - accuracy: 0.9210 - val_loss: 0.1135 - val_accuracy: 0.9720\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.2869 - accuracy: 0.9140 - val_loss: 0.0469 - val_accuracy: 0.9707\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 65s 650ms/step - loss: 0.2446 - accuracy: 0.9250 - val_loss: 0.0079 - val_accuracy: 0.9780\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.2318 - accuracy: 0.9255 - val_loss: 0.0046 - val_accuracy: 0.9710\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 61s 607ms/step - loss: 0.2903 - accuracy: 0.9115 - val_loss: 0.0132 - val_accuracy: 0.9707\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 64s 640ms/step - loss: 0.2608 - accuracy: 0.9230 - val_loss: 0.1314 - val_accuracy: 0.9680\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 64s 641ms/step - loss: 0.2683 - accuracy: 0.9196 - val_loss: 0.2294 - val_accuracy: 0.9690\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.2631 - accuracy: 0.9185 - val_loss: 0.0142 - val_accuracy: 0.9778\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.2500 - accuracy: 0.9150 - val_loss: 0.2395 - val_accuracy: 0.9780\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.2556 - accuracy: 0.9205 - val_loss: 0.5178 - val_accuracy: 0.9610\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.2825 - accuracy: 0.9115 - val_loss: 0.0121 - val_accuracy: 0.9617\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 64s 638ms/step - loss: 0.2743 - accuracy: 0.9135 - val_loss: 0.3787 - val_accuracy: 0.9700\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 64s 643ms/step - loss: 0.2699 - accuracy: 0.9140 - val_loss: 0.0884 - val_accuracy: 0.9720\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.2619 - accuracy: 0.9195 - val_loss: 0.3719 - val_accuracy: 0.9586\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.2581 - accuracy: 0.9160 - val_loss: 0.1089 - val_accuracy: 0.9730\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 64s 641ms/step - loss: 0.2634 - accuracy: 0.9145 - val_loss: 0.0250 - val_accuracy: 0.9810\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.2371 - accuracy: 0.9255 - val_loss: 0.0057 - val_accuracy: 0.9768\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.2827 - accuracy: 0.9160 - val_loss: 0.4310 - val_accuracy: 0.9690\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 62s 615ms/step - loss: 0.2510 - accuracy: 0.9210 - val_loss: 0.0721 - val_accuracy: 0.9760\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.2673 - accuracy: 0.9100 - val_loss: 0.0123 - val_accuracy: 0.9738\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 64s 637ms/step - loss: 0.2519 - accuracy: 0.9165 - val_loss: 0.0221 - val_accuracy: 0.9830\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.2356 - accuracy: 0.9240 - val_loss: 0.0169 - val_accuracy: 0.9738\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 66s 664ms/step - loss: 0.2615 - accuracy: 0.9121 - val_loss: 0.0268 - val_accuracy: 0.9800\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 64s 637ms/step - loss: 0.2358 - accuracy: 0.9290 - val_loss: 0.1443 - val_accuracy: 0.9750\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 0.2474 - accuracy: 0.9175 - val_loss: 0.0754 - val_accuracy: 0.9677\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.2416 - accuracy: 0.9245 - val_loss: 0.0338 - val_accuracy: 0.9740\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.2518 - accuracy: 0.9211 - val_loss: 0.1698 - val_accuracy: 0.9810\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 0.2211 - accuracy: 0.9320 - val_loss: 0.0446 - val_accuracy: 0.9798\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.2458 - accuracy: 0.9305 - val_loss: 0.2371 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "100/100 [==============================] - 63s 635ms/step - loss: 0.2432 - accuracy: 0.9215 - val_loss: 0.1120 - val_accuracy: 0.9770\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.2151 - accuracy: 0.9325 - val_loss: 0.0145 - val_accuracy: 0.9707\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.2412 - accuracy: 0.9250 - val_loss: 0.0012 - val_accuracy: 0.9820\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.2384 - accuracy: 0.9255 - val_loss: 0.3317 - val_accuracy: 0.9710\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 64s 641ms/step - loss: 0.2443 - accuracy: 0.9230 - val_loss: 0.0049 - val_accuracy: 0.9768\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 0.2434 - accuracy: 0.9255 - val_loss: 0.0035 - val_accuracy: 0.9810\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 66s 656ms/step - loss: 0.2259 - accuracy: 0.9265 - val_loss: 0.0013 - val_accuracy: 0.9800\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.2662 - accuracy: 0.9185 - val_loss: 0.0099 - val_accuracy: 0.9697\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 64s 641ms/step - loss: 0.2054 - accuracy: 0.9370 - val_loss: 0.4664 - val_accuracy: 0.9710\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.2057 - accuracy: 0.9345 - val_loss: 0.0999 - val_accuracy: 0.9690\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.2276 - accuracy: 0.9285 - val_loss: 0.0119 - val_accuracy: 0.9818\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.2359 - accuracy: 0.9255 - val_loss: 0.0384 - val_accuracy: 0.9700\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 61s 609ms/step - loss: 0.2540 - accuracy: 0.9160 - val_loss: 0.3341 - val_accuracy: 0.9710\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.2485 - accuracy: 0.9170 - val_loss: 0.0537 - val_accuracy: 0.9627\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 61s 606ms/step - loss: 0.2527 - accuracy: 0.9145 - val_loss: 0.0724 - val_accuracy: 0.9750\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 64s 640ms/step - loss: 0.2059 - accuracy: 0.9340 - val_loss: 0.2016 - val_accuracy: 0.9788\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 61s 608ms/step - loss: 0.2393 - accuracy: 0.9170 - val_loss: 0.0490 - val_accuracy: 0.9760\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.2453 - accuracy: 0.9200 - val_loss: 0.1385 - val_accuracy: 0.9820\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 61s 607ms/step - loss: 0.2171 - accuracy: 0.9300 - val_loss: 0.0594 - val_accuracy: 0.9627\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 61s 610ms/step - loss: 0.2233 - accuracy: 0.9286 - val_loss: 0.0036 - val_accuracy: 0.9770\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 62s 619ms/step - loss: 0.2494 - accuracy: 0.9240 - val_loss: 0.0054 - val_accuracy: 0.9740\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.2282 - accuracy: 0.9265 - val_loss: 0.0415 - val_accuracy: 0.9768\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.2186 - accuracy: 0.9265 - val_loss: 0.1008 - val_accuracy: 0.9720\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 60s 601ms/step - loss: 0.2008 - accuracy: 0.9405 - val_loss: 0.0408 - val_accuracy: 0.9730\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.2174 - accuracy: 0.9320 - val_loss: 0.0468 - val_accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 61s 608ms/step - loss: 0.2331 - accuracy: 0.9250 - val_loss: 0.1356 - val_accuracy: 0.9740\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.2356 - accuracy: 0.9325 - val_loss: 0.0612 - val_accuracy: 0.9770\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 59s 592ms/step - loss: 0.2365 - accuracy: 0.9271 - val_loss: 0.1275 - val_accuracy: 0.9818\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.1822 - accuracy: 0.9435 - val_loss: 0.0387 - val_accuracy: 0.9740\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.2088 - accuracy: 0.9290 - val_loss: 0.1987 - val_accuracy: 0.9770\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.2445 - accuracy: 0.9225 - val_loss: 0.1630 - val_accuracy: 0.9778\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 64s 643ms/step - loss: 0.2452 - accuracy: 0.9215 - val_loss: 0.1618 - val_accuracy: 0.9740\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 66s 657ms/step - loss: 0.2167 - accuracy: 0.9235 - val_loss: 0.2428 - val_accuracy: 0.9740\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.2428 - accuracy: 0.9215 - val_loss: 0.0068 - val_accuracy: 0.9758\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.2098 - accuracy: 0.9325 - val_loss: 0.0065 - val_accuracy: 0.9780\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 60s 604ms/step - loss: 0.1970 - accuracy: 0.9395 - val_loss: 0.0146 - val_accuracy: 0.9660\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.2197 - accuracy: 0.9285 - val_loss: 0.0115 - val_accuracy: 0.9808\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.2345 - accuracy: 0.9245 - val_loss: 0.0572 - val_accuracy: 0.9690\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.2343 - accuracy: 0.9280 - val_loss: 0.0074 - val_accuracy: 0.9700\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.2190 - accuracy: 0.9310 - val_loss: 0.0018 - val_accuracy: 0.9717\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 61s 609ms/step - loss: 0.2032 - accuracy: 0.9315 - val_loss: 0.4062 - val_accuracy: 0.9590\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 64s 640ms/step - loss: 0.1978 - accuracy: 0.9390 - val_loss: 0.0015 - val_accuracy: 0.9798\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.2155 - accuracy: 0.9245 - val_loss: 0.0033 - val_accuracy: 0.9720\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 60s 602ms/step - loss: 0.2219 - accuracy: 0.9236 - val_loss: 0.0190 - val_accuracy: 0.9780\n"
     ]
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 100,\n",
    "            validation_steps = 50,\n",
    "            verbose = 1,\n",
    "            callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZgU1bkG8PdlEBEVRSBGWWZASaJG4zKX6xKjUVRCEnFJjIJG44Jr3KO4KzdGjYnRGDXBLSooLomGLGpcMBpXBreIKxLAAcVRQFFQYOa7f3xVdk1PL1XdPdNDzft7nn6mq+pU1TlV1V+dOud0D80MIiKSXt2qnQEREWlfCvQiIimnQC8iknIK9CIiKadALyKScgr0IiIpp0DfBZGsIfkJycGVTFtNJDclWfGxwiRHkJwTmX6D5M5x0pawrxtInl3q+iL5dK92BqQ4kp9EJnsB+BxAczB9tJlNTrI9M2sGsE6l03YFZvbVSmyH5JEADjazXSPbPrIS2xbJpkC/GjCzLwJtUGM80swezpeeZHczW9UReRMpRtdj9anpJgVI/pzknSTvILkUwMEkdyD5DMklJN8l+VuSawTpu5M0knXB9KRg+f0kl5J8muSQpGmD5d8h+SbJj0heTfJJkoflyXecPB5NchbJxSR/G1m3huRvSH5I8m0AIwscn3NJTsmadw3JK4L3R5J8LSjP20FtO9+2GknuGrzvRfK2IG8zAWyXY7+zg+3OJLl3MH9LAL8DsHPQLPZB5NheGFn/mKDsH5K8j+RGcY5NkuMc5ofkwyQXkXyP5BmR/ZwXHJOPSTaQ3DhXMxnJf4fnOTiejwf7WQTgXJLDSE4LyvJBcNzWi6xfG5SxKVh+FcmeQZ43i6TbiOQykn3zlVdyMDO9VqMXgDkARmTN+zmAFQC+D795rwXgfwD8L/ypbSiANwGcEKTvDsAA1AXTkwB8AKAewBoA7gQwqYS0XwKwFMDoYNmpAFYCOCxPWeLk8S8A1gNQB2BRWHYAJwCYCWAggL4AHvfLOed+hgL4BMDakW2/D6A+mP5+kIYAdgOwHMBWwbIRAOZEttUIYNfg/a8APAagD4BaAK9mpT0AwEbBORkT5GHDYNmRAB7LyuckABcG7/cM8rg1gJ4ArgXwaJxjk/A4rwdgIYCTAKwJoDeA4cGyswC8BGBYUIatAWwAYNPsYw3g3+F5Dsq2CsCxAGrg1+NXAOwOoEdwnTwJ4FeR8rwSHM+1g/Q7BcsmArg4sp/TANxb7c/h6vaqegb0SnjC8gf6R4usdzqAu4P3uYL37yNp9wbwSglpDwfwRGQZAbyLPIE+Zh63jyz/M4DTg/ePw5uwwmWjsoNP1rafATAmeP8dAG8WSPs3AMcH7wsF+nnRcwHguGjaHNt9BcB3g/fFAv0tAH4RWdYb3i8zsNixSXicDwHQkCfd22F+s+bHCfSzi+ThBwCmB+93BvAegJoc6XYC8F8ADKZfBLBfpT9XaX+p6SY93olOkPwayb8Hj+IfA5gAoF+B9d+LvF+Gwh2w+dJuHM2H+SezMd9GYuYx1r4AzC2QXwC4HcBBwfsxAL7owCb5PZLPBk0XS+C16ULHKrRRoTyQPIzkS0HzwxIAX4u5XcDL98X2zOxjAIsBDIikiXXOihznQQBm5cnDIHiwL0X29fhlkneRnB/k4Y9ZeZhj3vHfipk9CX86+CbJrwMYDODvJeapy1KgT4/soYV/gNcgNzWz3gDOh9ew29O78BonAIAk0TowZSsnj+/CA0So2PDPOwGMIDkQ3rR0e5DHtQDcA+ASeLPK+gD+GTMf7+XLA8mhAK6DN1/0Dbb7emS7xYaCLoA3B4XbWxfeRDQ/Rr6yFTrO7wDYJM96+ZZ9GuSpV2Tel7PSZJfvMvhosS2DPByWlYdakjV58nErgIPhTx93mdnnedJJHgr06bUugI8AfBp0Zh3dAfv8G4BtSX6fZHd4u2//dsrjXQBOJjkg6Jg7s1BiM1sIb164GcAbZvZWsGhNeLtxE4Bmkt+DtyXHzcPZJNenf8/ghMiydeDBrgl+zzsSXqMPLQQwMNopmuUOAEeQ3IrkmvAb0RNmlvcJqYBCx3kqgMEkTyDZg2RvksODZTcA+DnJTei2JrkB/Ab3HrzTv4bkOERuSgXy8CmAj0gOgjcfhZ4G8CGAX9A7uNciuVNk+W3wpp4x8KAvCSnQp9dpAA6Fd47+AV6jbVdBMP0RgCvgH9xNALwAr8lVOo/XAXgEwH8ATIfXyou5Hd7mfnskz0sAnALgXniH5g/gN6w4LoA/WcwBcD8iQcjMXgbwWwDPBWm+BuDZyLoPAXgLwEKS0SaYcP0H4E0s9wbrDwYwNma+suU9zmb2EYA9AOwP7/x9E8AuweLLAdwHP84fwztGewZNckcBOBveMb9pVtlyuQDAcPgNZyqAP0XysArA9wBsBq/dz4Ofh3D5HPh5XmFmTyUsuyDTwSFSccGj+AIAPzCzJ6qdH1l9kbwV3sF7YbXzsjrSF6akokiOhD+KfwYfnrcKXqsVKUnQ3zEawJbVzsvqSk03UmnfBDAb/kg/EsA+6jyTUpG8BD6W/xdmNq/a+VldqelGRCTlVKMXEUm5TtdG369fP6urq6t2NkREViszZsz4wMxyDmfudIG+rq4ODQ0N1c6GiMhqhWTeb4er6UZEJOUU6EVEUk6BXkQk5RToRURSToFeRCTlFOhFRFJOgV5EJOUU6EVEOoFJk4BbbgHa41dpFOhFUuSVV4BDDgGWLat2TjrW8uXAqlXVzkU8n38ONGf908SVK4GzzgJuvRVgO/wfOAV6kRS59lqvGU6c2PH7fvpp4Pbbi6crlRlw3XXAG2+0nv/OO8AmmwCDBgFnngm8/nr75SHbypXAuecCxx/vr5NPLrx/M6C+HjjssNbz770XaGz09dtFtf87efZru+22MxFxZ55ptv/+Zs3NxdO2tJgNHGgGmG28sdny5e2fv9Cnn/o+AbOrr86f7vPPzZ57zvOa1L/+5dvfcEOzN9/0eZ98YrbNNmbrrmv2ve+Z1dR4msMOM1u1qrSyJHH//b6/9dc369fPbM01/f2//pU7/bPPenrAj0Noxx3NNtkk3nnOB0CD5YmrVQ/s2S8F+uL++U+zm26Kl7a52eyxx8yuu668i6g9vfKK2RlnmK1cWe2cVF5zs9nNN5u9/37ydRctMuvZ0z+l115bPP3zz3vagw+Ov06lXHaZ7/N//seMNLv99tzpzjzT033962a33GK2YkXbNAsX+vWwcGHr+Ycc4gG9f3+zQYPM/vtfsx/+0Pf3t795mnffNTv9dN/HEUfkv+bvv9/svPPMPvqo7bKVKz0gX3qp2cknF75h/uxnZj16+I3OzGz2bLOvftXnTZnSNv3JJ/uyfv3Mdt3Vb3hh8L/qqvz7iUOBPkU+/zxTc5o2rfWyc881W3ttrx2cdJLZ2Web1dVlahCPPVbZvLz8stn8+fHTL1tm9s47red98EEmj9n5a272D+TixZXJ6+zZ5W8nqXPO8bIddVTyda+6KhMU11nHA1to/nyz6dNbp7/oIg96Cxea7bCD2eDBuQNpOVpazI47zq+vsMa8aJHXYkeN8nP8rW+Zde9u9sADrdf98EMvx447epkAs9pas3//u3WaLbf0ZePGZeYvXmy21lpmxx5r9uKLvr911/V0l13WNp/nnefLfvrTtk8PM2ea9erlywcMMLv3Xr/WHn7Yb5K9e2c+M4DZaaflPx7bbmu2yy5ty/nNb/q6d9yRmb9qldlGG5nts48/9QBmf/+72ZgxXpZcN50kulygb2nxu/qzz7ZddtllZn/+c7Jt5app/uc/Zkce6Rd2OVpa/C5/1FFm11/vF3Ghx9rJk/2s9e5tNnSoP7qamf3lLz5/l13MdtrJPxSk2YgRXvvv0aPtBbtsmdkvfmH22mtt97N0qdnHH+evEf3jH2ZrrOEf2Ozjc/31XtNZsiQz77XXzDbbzNe57rrMcR0xwvPWvbuvE3XnnV6mXr38+DzzjN/crr3WbPz4+DeZSZN8v1/+crIbUy733mv23e+a7buv1zDPOiv/BzQ8V+ut5zfg6PEw8+P/3HNesz37bLNHHsksa2kx22ILryHPmeMBcsQIn3/zzX7+u3c3e+utzDrbbecB3szPD2B2443xytXc7OuMGWP20EP50/3pT5kA+OMfe/AaP96vtZde8jRLlph94xsevKI31wsv9PVeftnL8fe/m226qZfjd7/z9errvfnj29/2+bNm+brXXuvrzpjh088+68f10ENzf15aWsxOPdXXOe64TK186VK/Dr/0JbP77jPbaitPs8EGmXN1+OFeG3/vPb+xkLmbYj780JdNmNB22fLlfu423jhT2582zfcxZYpX2DbZxGzYMC/nyScXOjvxdLlA/8EHXrKxY1vP//RT/8BvsUX8bZ17rgfU7IB3/PG+jwsuKC+vTzzh2wkf0QH/0OfS0uIXz1e+krloTj7Z7O23vYaz3XaZC3rlSq9phfbayy+qqN//3rcRXmiLFnmt+oc/9HmAX8i9e5v95CdmCxb4etOmeX4HDPA011yT2eYLL2TW3Wgjs7vv9uAYPnJ/+9u+7Cc/8X2GwWj33c0237x1/vbbz9tjDz+89fEJX+ed1/YYPfigB5ClS/14hU0KO+zgwXaHHcw++yyT/t13zZ56yq+ZQubNMxs92rc1eLDf4OrqzLp188Cf3R783HOe55139hpr9nH6+GO/rqLl6d3bg7qZ2ZNP+rzrr/fpMNCFgWmnnfwGeOCBvnz+fJ9/ySU+3dLi18PQoR6kwuPx1FNmxxzjZdhuO/+M/OxnHnQAL0+vXmZPP932GHz8sfcBbLWVX/eA2Q9+4JWK7M/anDlenh139Gvx44/N+vQx23vv1ukWL/a29bDtvXt3s7/+1a+1nj39ZmLmNeett2697qefFq4URYP95pubNTSYHXSQl/HRRz3NihVmv/qV2QEHeADOrrh98okfm7o6L0PUPff4tqNPJFGPP+7LL77Yp8eN82swDPxhRYb0z3C5ulygnzHDS/blL7e+EB58MPOhev314ttZvtwvTsBrk1HDhvn8Ndcs7yQdcIAH6U8+8Q6mESM8QOaqST/1VOuAcfzxfpFsuqlvo1DTxDXXtC339tubfe1rfgGSfhMEvMynnGJ2+eVm55/vQXmNNbxWedppfrFusYVZU5MH7g028NrNihXeMbbhht6PsM02meM9fLgHy+Zm32Y4/9hjPS9XXOHTYfPE0qX+QT/hBJ/+8EOvmT/4oG/nf//X8x+1aFGmM65790zzwAEHeHC/6y6fPvpo/7BddFHmER4w69vXg/a0aZnr5oMPPL/rrOMB7Ze/bN0cEh7X00/PzJs2zc9hXZ23zbe0eKDacsvMdk8/3Y/5jTf6084bb/jNcOed/aZx6KG+z6VLPX1zs9luu/kxueIKnw6bhZ5/3uwPf/D3r7ySyccDD2Ruut26eS0W8HLsu6/Znnt6wAe8qeGOO7xpbZNN/Jy++mrr4xsGzaee8umLLsoc61yfgUmTfPmECX4t5fochWW76CIv7113ZeafdprnO3wy+t3v2q4bx/33e82abB144/r3v33d7Oa3Y4/1PBdqHtt7bz+v8+f7MR0zJrOspcWfwKPzytHlAn308XLmzMz8M87IBIKw5lNIeKFm1x5nz/Z5Z5zhQe/73y++reZms1tvbd3B1NjoH5Jok0q4z1wfiB/9yB8tww//0qWZ9u2//KXw/ufO9XS//KVPv/aaT19+uU+/8IIH/BtvzNQ4ot580y9awG9yYe3+pZf8w3jiiWY//7kvD5vGVq70dubx41vXos288+yUU/wR1swDXfTDPGWKT+cbvXDuub7faPt9GBCuvto7/Xbc0dNFb5rjx3uafv3sixrpvfea/frX/kHecEP74gng+OP9/AIeGPPdSI87ztNceaWP9gDMhgzx5r3QxIk+/8kn/Zrs3t2b/qJuvdXT/OxnHtCPPrr18mXLWl8/S5Z48Bg50m9QQ4e2reEuXOjH+oILPKDcfHPbpqbsprdZs/w4DBrk7dYLFniTYk1N63ZzM7/B3HBD7uNi5jXomhrP5+67509n1rZy8/77fvzXWMOPR/QJNalFi7xz9vDDSxuUcMYZfm7CJwEz73QdNarwejNn+nUaVnr++tfWy0sZfZRPlwv0Ye0w/NCH6uu9xjR8uDeBRLW0tD3o3/qW12522MFrZKGwyeO11zxw5jqB2cI20512ytQAzj/fawphO6RZplY6fnzr9efN8/nRmqOZ5+G++wrvO7T11l5zM/Pt19RkAnZczz3XdgTJMcf4tnr08NpzqTbd1Ow73/H3++3nT2T5hsiFQ+2i/S0HHui11kIf5FWrfNvDh+funF6+3JtJamu9TAcf3LqWnMuKFR7EwtrtWWe1vVkuXeo1u4MP9qegPn38iSiqpcVv5uG1+/zzhfdrlqkp19R4B2mlPP98605J0pvePvww2XYWL848NUSDZFzhU8vBBydft5KWLfNrYqut/BpqbPR8/frXxdc96ij74kk5rNi0hy4X6E880R+p6uq8h9vMAyjpNZtLLvGSz53ry1pafKzyjjtmOjfDGu9ll/mjHpAJivvu6xdvS4ufuM028xpcWNPOZZ99Mu3MZ5zh6224odfEsu2+uzepRJ15ptcMwjbcUpx/vm/jvff8UTbXvkvx/vvedNS3b9shcUmcdJIfo4ULWzfb5PL5517bC5t+VqzwPPzkJ6XvP2rlyradp4UsWuQ3z5dfzp8mrPkD3iGdbzuDBrVtlspn2bJMX0m0M7cSmpq8qezqq/0z9fDDpW3npZf8ya6U2uvixf7EHHb0VlPY9Pf733sHOuBPwsXMn+/X6jHHtG/+ulygHz3a22ePOMI//KtW+eM54B0kYTNBOG71jjsyH8B99vEa4amn+iPjwoX+2Bp2Gq5c6TWd6GP3Y495AB05Mnd73fz5XuM64ww/2YC3wQJth6CZZYZehe3pjY3elvyjH5V3XKZP9+2OGeN/7767vO1FPf988ZpvMf/8Z6b2VqjZJvTd7/pTgFmmczrJiKqO9tJLnsdtty38ZZ4lS5INKb3nHn/6rPRQSmmtpcVbBPr18xjTr1/8ZqA5czKVyPbS5QL9N77hQeD2272E06d77bBXr8yj0xZb+BcWFi/2mvV22/ljGOBtx337+ugTs8w3DvfbLzMaIjtIhm2whx3WtuYStl2/+aY3DYTtdcOG5b5Qwvb0cHzwj3/szSLljgNvbs6Mwe/Tp227ebV99lmmTbxQs03oyivtiw7cU0/1Y1ToqaozuOEGr2jI6mnGjEynbhgfOosuF+jXX9870t5910t46aXevLLXXpk0YWfeAQf434YGD9BHH52p3UfHE48b522s48d7+lwdQ+GQs3POycxrbva2vd12y8x76y1/PL/llvxl2HZb7xt47jnfZnabfanGjfPtHX98ZbZXaeEQxkLNNqGZMz3txIl+04yeX5H2cvjh9kUTTmfSpQL9kiXWanTJFltkxh6H88wyXxcHWndirVjhHYJbb926th1+IWmddfK3n7a0ZDpejj3Wa6gPPODTd97ZNm0h4bcct9rKnziyx/CWato0r/m++GJltldpN97ox+uJJ4qnbWnx9unwCanQb6yIVMr773sTbLHvXnS0LhXow3bQcDzuiSdmAnpDQyZdS4t3oA4Y0DaIhp2sUZ984gESKPwlqZUrM7+1sd123jzUv3/y3vawHGHfQCWV+23e9rRqVf4voOQSDmcEyuuoFlndFQr0qfuZ4rlz/W9trf/dbTf/26cPsPXWmXQkMHUq8MgjwLrrtt4GCfTo0Xre2msDu+7q7/fcM//+u3cHLr/cf3Z01izgscf8J0mzt1fMllsCw4YB22wDHHposnWLWWutym6vkmpqgJ12ip9+jz3875ZbZs65iLTWvdoZqLQ5c/xvXZ3/3WUXoFs34Nvf9iAS9fWvJ9v2uHH+Dw6GDy+edp99gOefB668Ejj11GT7Afxm8+ijQM+ebfMtGSNG+M119Ohq50Sk84oV6EmOBHAVgBoAN5jZpVnLawHcBKA/gEUADjazxmBZM4D/BEnnmdneFcp7TnPneo21f3+fXn994I9/bF2bL9X++/srrqFDgd/+tvT9DRxY+rpdxZe+BMyYAWy6abVzItJ5FQ30JGsAXANgDwCNAKaTnGpmr0aS/QrArWZ2C8ndAFwC4JBg2XIzq0CYjWfOHH+Ej/47rkMOyZtcUmCrraqdA5HOLU4b/XAAs8xstpmtADAFQPaD8uYAHgneT8uxvMPMnau2WhGRqDiBfgCAdyLTjcG8qJcAhI0a+wJYl2TfYLonyQaSz5DcJ9cOSI4L0jQ0NTUlyH5bYY1eRERcnECf63+SW9b06QB2IfkCgF0AzAcQ/k/2wWZWD2AMgCtJbtJmY2YTzazezOr7h43rJfj0U+CDDzIdsSIiEq8zthHAoMj0QAALognMbAGA/QCA5DoA9jezjyLLYGazST4GYBsAb5ed8xyyh1aKiEi8Gv10AMNIDiHZA8CBAKZGE5DsRzLc1lnwETgg2YfkmmEaADsBiHbiVlQY6FWjF5FyTJ7scaRbN/87eXK1c1SeojV6M1tF8gQAD8KHV95kZjNJToB/E2sqgF0BXELSADwO4Phg9c0A/IFkC/ymcmnWaJ2KCsfQq0YvIqWaPNm/M7NsmU/PnevTADB2bPXyVQ76N2c7j/r6emtoaChp3fHjgSuuAD77zO/EIiJJ1dVlWgeiamszlcnOiOSMoD+0jVSFwzlzgMGDFeRFStHZmyvaI3+5tjlvXu60+eZXQrsf+3w/glOtVzk/arb99sX/L6VIR5o0yX+mmvS/kyZVO0e5TZrU+h+lAz7dWfKbK3/h78JHj2uS452vzH37tp4XvmprO65spRx7dJVfr9xoI/+taJHOoJLBs71vGLW1HRvc4grLnStv2cf12GOTHe982+3bt2NvepU69l0i0C9f7qWZMKGk1UUqplhwSvoB7ojadlg7zn6R5W23nBtUrnKX8sp3vAuVuSOexIpdJ0mPfZcI9O+9ZzZ8uP//TJFqiROckn6AO6K2XWgfpQa9cm9QcWrycV7Zx7vSN+JSxLlOVKOXqii3drY6tFWXK05wSvoBLqW2nfR45wvKuZpDcrWN59p3ueXPV+5SavTRPBXabkf1SxS7TtRGL1URt3aWK8B09o6+uAoFzyRtyUnLHbdGXyiYrbGGtz0XCvy5ypc0IFXyiaZYs0acIJ/vZlXohpBEqRWYQvkvtSKkQC9lixNsOssohkoqFDzDIBe3LbnUD3CcESdJ27Pj3nDiBtS4N4Y45z3uMS+2ryR5StKcFid/xbRHc5wCvRRVrGYSp/kgaZtqJTq98q1fStNFnCeRXK+amsoE1Tj5yxVcSm3iiBNUkpzTOMeq2FNg376Z/82c76aWvW6+p8W4QT5JgI3btl7s+muPp1wFeikozkUXpwaSNOCUO4wtSbtyoe0mfRJJGkyL3XyyA12hJpZKdVBGz0Gh/SV9Uih00ytn+4UCcTk36Vw3hkLnp9hNPXzFqelXut9KgV4KijPiItfFm13TSjouudwmnXz7y/dhzLfdSgfPXPtLclMqFCAq1UGZJOiFN4Nc10C5QS5uvio1UinftVvq+Ul6PbTnoAQFeimo0Ic3X3DP9WEuVJPOdYGXOnY7aZCIvqI12GgAa6+AGUp6U8oOEMW2U+jc5WoOKXaMym0OSdrckuQYlHtNJ3lSiluDT3JdFLpOyqFA3wkkeTzvaEmDZqEac5waS5KOtFzrFgsSlf5w5gpg+fabtI8j7j6TlD/X8Svn5hjdZpJ8FBoVlDQ4ttdIpUqdnzjpkj5pJqVAX2XFPhTF2girnb9SAlIl9hX9gCetSbZHE0c5w0XLCbJJhlG2Zz6SfvGolBsUEG8oaDFJz1HSGn32TT3OMNRyPjdxKNBXWZwPV9yOyUreDPK1wxZ7lVMzSRpowjLGCRKVGo2SJMiV84WkOK9igbvS+Sil7yRO7TnJ6JdKVXCSHJtyO/ZzrR9tOiv02VKNvhMpJcB2xONysW8pFspbKSNNShnVEpU0+IbHu1i6QjWvJPtrz8frONdDrj6ESj/hFWtGTFobjpO+2HnvDF+gizPqptB5KGX0j9roO5FSHtXbozkkzuNh3IsmyQiZYj8Hmy8g5brw26PTq9hxTtJUVM5NLK44NeBSrrlKKuVJoVD6QtduZ+inai8dWW4F+jIl7dgptE7SV9w2wFzpC31IK/XLfUkfeZPMr8TxyT4ecWrM7d1XEieIl3LNdWbVvnFVS6kjy0qhQF+mUk5WoUfVuO3hpXYsxqmRVyqQlDKWvdgjctwyZo8qWZ0CSbGbSUcGiI5SrcEG1dSRN2wF+jJVskYfXSfJ+PW4r7hfx69UYCylzb2cbSb9Ua7VVdpq9F1VR1ZAFOjLVKk2+kp+iSbXzSBJ00dtrTeXlBsYS6nRl7rNrhTkVrcnFMmvoyogCvSBcg54OaNukv6wUdxAXerwyEoGjnKHpSXZZlcLcml6QpH2p0BvpdfKKznyIO46SUfXlDPCp5LDBivZqakgJ5JM2YEewEgAbwCYBWB8juW1AB4B8DKAxwAMjCw7FMBbwevQYvtqr0CftDkg7o0hGpiTfksxn6Tj5QvdGIq1oa/OnXsiklFWoAdQA+BtAEMB9ADwEoDNs9LcHQZxALsBuC14vwGA2cHfPsH7PoX2116BPukohjjD9eIE0lJrzElqtHGGSrZnjV5Eqq9QoO+G4oYDmGVms81sBYApAEZnpdk8qNEDwLTI8r0APGRmi8xsMYCHgqeDDjd4cP75kycDdXVAt27+d/JkYN683OnnzgXGjfO/gIfLQvJtp5ixY4E5c4CWFv87dmz+tIXKFm5n0iSgV6/Wy3v1Ai6+uLT8icjqI06gHwDgnch0YzAv6iUA+wfv9wWwLsm+MdftEBdfnDvQjRqVCdxmmUC+wQa5t1NTAyxbFn+/+YJwJeUrWzSIjx0LTJwI1NYCpP+dOLHwDURE0iFOoGeOedn12NMB7ELyBQC7AJgPYFXMdUFyHMkGkg1NTU0xspRcdlHwS+EAAA5wSURBVKDr2xdYay3guuvaBu5wOlfwbG6Ov8+OqjHHDeJJnhJEJD3iBPpGAIMi0wMBLIgmMLMFZrafmW0D4Jxg3kdx1g3STjSzejOr79+/f8IixBcGuttuA5YvBz78MH/aRYtyB8/a2sL7YHBr6+gas4K4iOTTPUaa6QCGkRwCr6kfCGBMNAHJfgAWmVkLgLMA3BQsehDAL0j2Cab3DJZX1TnnFG9+Cdu3cwXMceNar096s09trdfgFWRFpDMpWqM3s1UAToAH7dcA3GVmM0lOILl3kGxXAG+QfBPAhgAuDtZdBOD/4DeL6QAmBPOqqlgHKelt9WHHbFSuZpLbbvNAr5q0iHRGtGLDRjpYfX29NTQ0VGx7kyd7DX7ePK+lX3yxT4ejZrKFtfNQr17qtBSRzo/kDDOrz7UsThv9amvy5NwjakaNyt3R2rdv2+GSy5b5jUFEZHWV6kCfqy1+2TLgH//I3dG6KE+jUqlj4UVEOoNUN91065b7C02kj07JVleXu0mnttbb30VEOqsu23RT6BujucT54pGIyOom1YE+aeDWt0dFJI3ijKNfbYUBOnvUTaHAnW/svIjI6irVgR5Q4BYRSXXTjYiIKNCLiKSeAr2ISMop0IuIpJwCvYhIyinQi4iknAK9iEjKpTLQ5/pn3yIiXVXqvjAV/jRx+KuV4U8TA/rilIh0Tamr0ef7aWL9pryIdFWpC/T5fjtevykvIl1V6gJ90p8mFhFJu9QFev2mvIhIa6kL9PpNeRGR1lI36gbQTxOLiESlrkYvIiKtxQr0JEeSfIPkLJLjcywfTHIayRdIvkxyVDC/juRyki8Gr99XugAiIlJY0aYbkjUArgGwB4BGANNJTjWzVyPJzgVwl5ldR3JzAP8AUBcse9vMtq5stkVEJK44NfrhAGaZ2WwzWwFgCoDRWWkMQO/g/XoAFlQuiyIiUo44gX4AgHci043BvKgLARxMshFem/9pZNmQoEnnXyR3LiezIiKSXJxAzxzzLGv6IAB/NLOBAEYBuI1kNwDvAhhsZtsAOBXA7SR7Z60LkuNINpBsaGpqSlYCEREpKE6gbwQwKDI9EG2bZo4AcBcAmNnTAHoC6Gdmn5vZh8H8GQDeBvCV7B2Y2UQzqzez+v79+ycvhYiI5BUn0E8HMIzkEJI9ABwIYGpWmnkAdgcAkpvBA30Tyf5BZy5IDgUwDMDsSmVeRESKKzrqxsxWkTwBwIMAagDcZGYzSU4A0GBmUwGcBuB6kqfAm3UOMzMj+S0AE0iuAtAM4BgzW9RupRERkTZolt3cXl319fXW0NBQ7WyIiKxWSM4ws/pcy/TNWBGRlFOgFxFJOQV6EZGUU6AXEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGUU6AXEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGUU6AXEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGUU6AXEUk5BXoRkZRToBcRSblYgZ7kSJJvkJxFcnyO5YNJTiP5AsmXSY6KLDsrWO8NkntVMvMiIlJc92IJSNYAuAbAHgAaAUwnOdXMXo0kOxfAXWZ2HcnNAfwDQF3w/kAAWwDYGMDDJL9iZs2VLoiIiOQWp0Y/HMAsM5ttZisATAEwOiuNAegdvF8PwILg/WgAU8zsczP7L4BZwfZERKSDxAn0AwC8E5luDOZFXQjgYJKN8Nr8TxOsC5LjSDaQbGhqaoqZdRERiSNOoGeOeZY1fRCAP5rZQACjANxGslvMdWFmE82s3szq+/fvHyNLIiISV9E2engtfFBkeiAyTTOhIwCMBAAze5pkTwD9Yq4rIiLtKE6NfjqAYSSHkOwB71ydmpVmHoDdAYDkZgB6AmgK0h1Ick2SQwAMA/BcpTIvIiLFFa3Rm9kqkicAeBBADYCbzGwmyQkAGsxsKoDTAFxP8hR408xhZmYAZpK8C8CrAFYBOF4jbkREOhY9Hnce9fX11tDQUO1siIisVkjOMLP6XMv0zVgRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGUU6AXEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGUU6AXEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGUU6AXEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGUixXoSY4k+QbJWSTH51j+G5IvBq83SS6JLGuOLJtaycyLiEhx3YslIFkD4BoAewBoBDCd5FQzezVMY2anRNL/FMA2kU0sN7OtK5dlERFJIk6NfjiAWWY228xWAJgCYHSB9AcBuKMSmRMRkfLFCfQDALwTmW4M5rVBshbAEACPRmb3JNlA8hmS++RZb1yQpqGpqSlm1kVEJI44gZ455lmetAcCuMfMmiPzBptZPYAxAK4kuUmbjZlNNLN6M6vv379/jCyJiEhccQJ9I4BBkemBABbkSXsgspptzGxB8Hc2gMfQuv1eRETaWZxAPx3AMJJDSPaAB/M2o2dIfhVAHwBPR+b1Iblm8L4fgJ0AvJq9roiItJ+io27MbBXJEwA8CKAGwE1mNpPkBAANZhYG/YMATDGzaLPOZgD+QLIFflO5NDpaR0RE2h9bx+Xqq6+vt4aGhmpnQ0RktUJyRtAf2oa+GSsiknIK9CIiKadALyKScgr0IiIpp0AvIpJyCvQiIimnQC8iknIK9CIiKadALyKScgr0IiIpp0AvIpJyCvQiIimnQC8iknIK9CIiKadALyKScgr0IiIpp0AvIpJyCvQiIimnQC8iknIK9CIiKadALyKScgr0IiIpp0AvIpJysQI9yZEk3yA5i+T4HMt/Q/LF4PUmySWRZYeSfCt4HVrJzIuISHHdiyUgWQPgGgB7AGgEMJ3kVDN7NUxjZqdE0v8UwDbB+w0AXACgHoABmBGsu7iipRARkbzi1OiHA5hlZrPNbAWAKQBGF0h/EIA7gvd7AXjIzBYFwf0hACPLybCIiCQTJ9APAPBOZLoxmNcGyVoAQwA8mmRdkuNINpBsaGpqipNvERGJKU6gZ455liftgQDuMbPmJOua2UQzqzez+v79+8fIkoiIxBUn0DcCGBSZHghgQZ60ByLTbJN0XRERaQdxAv10AMNIDiHZAx7Mp2YnIvlVAH0APB2Z/SCAPUn2IdkHwJ7BPBER6SBFR92Y2SqSJ8ADdA2Am8xsJskJABrMLAz6BwGYYmYWWXcRyf+D3ywAYIKZLapsEUREpBBG4nKnUF9fbw0NDdXOhojIaoXkDDOrz7VM34wVEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGUU6AXEUm51AT6yZOBujqgWzf/O3lytXMkItI5FP1m7Opg8mRg3Dhg2TKfnjvXpwFg7Njq5UtEpDNIRY3+nHMyQT60bJnPFxHp6lIR6OfNSzZfRKQrSUWgHzw42XwRka4kFYH+4ouBXr1az+vVy+eLiHR1qQj0Y8cCEycCtbUA6X8nTlRHrIgIkJJRN4AHdQV2EZG2UlGjFxGR/BToRURSToFeRCTlFOhFRFJOgV5EJOU63T8HJ9kEYG4Zm+gH4IMKZWd10RXLDHTNcnfFMgNds9xJy1xrZv1zLeh0gb5cJBvy/Sf0tOqKZQa6Zrm7YpmBrlnuSpZZTTciIimnQC8iknJpDPQTq52BKuiKZQa6Zrm7YpmBrlnuipU5dW30IiLSWhpr9CIiEqFALyKScqkJ9CRHknyD5CyS46udn/ZCchDJaSRfIzmT5EnB/A1IPkTyreBvn2rntdJI1pB8geTfgukhJJ8NynwnyR7VzmOlkVyf5D0kXw/O+Q5pP9ckTwmu7VdI3kGyZxrPNcmbSL5P8pXIvJznlu63QXx7meS2SfaVikBPsgbANQC+A2BzAAeR3Ly6uWo3qwCcZmabAdgewPFBWccDeMTMhgF4JJhOm5MAvBaZvgzAb4IyLwZwRFVy1b6uAvCAmX0NwDfg5U/tuSY5AMCJAOrN7OsAagAciHSe6z8CGJk1L9+5/Q6AYcFrHIDrkuwoFYEewHAAs8xstpmtADAFwOgq56ldmNm7ZvZ88H4p/IM/AF7eW4JktwDYpzo5bB8kBwL4LoAbgmkC2A3APUGSNJa5N4BvAbgRAMxshZktQcrPNfz/ZKxFsjuAXgDeRQrPtZk9DmBR1ux853Y0gFvNPQNgfZIbxd1XWgL9AADvRKYbg3mpRrIOwDYAngWwoZm9C/jNAMCXqpezdnElgDMAtATTfQEsMbNVwXQaz/lQAE0Abg6arG4guTZSfK7NbD6AXwGYBw/wHwGYgfSf61C+c1tWjEtLoGeOeakeN0pyHQB/AnCymX1c7fy0J5LfA/C+mc2Izs6RNG3nvDuAbQFcZ2bbAPgUKWqmySVokx4NYAiAjQGsDW+2yJa2c11MWdd7WgJ9I4BBkemBABZUKS/tjuQa8CA/2cz+HMxeGD7KBX/fr1b+2sFOAPYmOQfeLLcbvIa/fvB4D6TznDcCaDSzZ4Ppe+CBP83negSA/5pZk5mtBPBnADsi/ec6lO/clhXj0hLopwMYFvTM94B33kytcp7aRdA2fSOA18zsisiiqQAODd4fCuAvHZ239mJmZ5nZQDOrg5/bR81sLIBpAH4QJEtVmQHAzN4D8A7JrwazdgfwKlJ8ruFNNtuT7BVc62GZU32uI/Kd26kAfhyMvtkewEdhE08sZpaKF4BRAN4E8DaAc6qdn3Ys5zfhj2wvA3gxeI2Ct1k/AuCt4O8G1c5rO5V/VwB/C94PBfAcgFkA7gawZrXz1w7l3RpAQ3C+7wPQJ+3nGsBFAF4H8AqA2wCsmcZzDeAOeD/ESniN/Yh85xbedHNNEN/+Ax+VFHtf+gkEEZGUS0vTjYiI5KFALyKScgr0IiIpp0AvIpJyCvQiIimnQC8iknIK9CIiKff/NkllUf1N5bwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def predict(model, image_path):\n",
    "    img = image.load_img(image_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x /= 255.\n",
    "    \n",
    "    y_prob = model.predict(x)\n",
    "    y_classes = y_prob.argmax(axis = -1)\n",
    "\n",
    "    for i in label_map:\n",
    "        if label_map[i] == y_classes[0]:\n",
    "            return i\n",
    "    \n",
    "    return \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, '/home/eeshan/Pictures/cat_1.jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
